import 'dotenv/config';
import fs from 'fs';
import path from 'path';
import { OpenAI } from 'openai';

function cosineSimilarity(vec1, vec2) {
  const dotProduct = vec1.reduce((sum, val, i) => sum + val * vec2[i], 0);
  const normA = Math.sqrt(vec1.reduce((sum, val) => sum + val * val, 0));
  const normB = Math.sqrt(vec2.reduce((sum, val) => sum + val * val, 0));
  return dotProduct / (normA * normB);
}

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export default async function handler(req, res) {
  if (req.method === 'OPTIONS') {
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
    res.setHeader('Access-Control-Allow-Headers', 'Content-Type');
    return res.status(200).end();
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method Not Allowed' });
  }

  const { question } = req.body;

  if (!question) {
    return res.status(400).json({ error: 'Missing question' });
  }

  try {
    const dataPath = path.join(process.cwd(), 'text_data.json');
    const rawData = fs.readFileSync(dataPath, 'utf8');
    const textData = JSON.parse(rawData);

    const embeddingResponse = await openai.embeddings.create({
      model: 'text-embedding-ada-002',
      input: question
    });
    const questionEmbedding = embeddingResponse.data[0].embedding;

    console.log("ğŸŸ¡ ì‚¬ìš©ì ì§ˆë¬¸:", question);
console.log("ğŸŸ¡ textData í•­ëª© ìˆ˜:", textData.length);
console.log("ğŸŸ¡ ì²« ë²ˆì§¸ í•­ëª©:", textData[0]);
console.log("ğŸŸ¡ questionEmbedding ê¸¸ì´:", questionEmbedding.length);

    const scored = textData.map(item => ({
      text: item.text,
      score: cosineSimilarity(questionEmbedding, item.embedding)
    }));
    const topTexts = scored
      .sort((a, b) => b.score - a.score)
      .slice(0, 5)
      .map(item => item.text);

      console.log("ğŸŸ¢ ìœ ì‚¬ë„ ìƒìœ„ í•­ëª©:");
scored
  .sort((a, b) => b.score - a.score)
  .slice(0, 5)
  .forEach((item, index) => {
    console.log(`#${index + 1}: ì ìˆ˜ =`, item.score.toFixed(4));
    console.log(item.text.slice(0, 100) + '...');
  });


      let systemPrompt = '';
    let userPrompt = '';

    if (topTexts.length > 0 && scored[0].score > 0.75) {
      // ë²¡í„° ìœ ì‚¬ë„ ë†’ì€ ìë£Œê°€ ìˆì„ ë•Œ â†’ ì§€ë„ì„œ ê¸°ë°˜ ë‹µë³€
      systemPrompt = 'ë„ˆëŠ” ì´ˆë“±í•™êµ ìˆ˜í•™ ì§€ë„ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ìˆ˜í•™ ì „ë¬¸ ì±—ë´‡ì´ì•¼.';
      userPrompt = `ì§ˆë¬¸: ${question}\n\nì§€ë„ì„œ ë°œì·Œ ë‚´ìš©:\n${topTexts.join('\n---\n')}`;
    } else {
      // ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶ˆì¶©ë¶„í•  ê²½ìš° â†’ ì¼ë°˜ ë‹µë³€ìœ¼ë¡œ fallback
      systemPrompt = 'ë„ˆëŠ” ì¹œì ˆí•˜ê³  ì§€ì ì¸ AI ì±—ë´‡ì´ì•¼. ì´ˆë“±í•™ìƒì´ë‚˜ ì„ ìƒë‹˜ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ëª…í•´ì¤˜.';
      userPrompt = `ì§ˆë¬¸: ${question}`;
    }

    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ]
    });

    console.log("ğŸ§  GPT ì‘ë‹µ ì „ì²´:", JSON.stringify(completion, null, 2));

    return res.status(200).json({ answer: completion.choices[0].message.content });

  } catch (error) {
    console.error(error);
    return res.status(500).json({ error: 'Internal Server Error' });
  }
}
